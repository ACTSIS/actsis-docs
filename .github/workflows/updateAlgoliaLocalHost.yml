name: Algolia Scraping (Modo Desarrollo)

on:
  workflow_run:
    workflows: ["pages-build-deployment"]
    types:
      - completed
  workflow_dispatch:

defaults:
  run:
    working-directory: ./website
jobs:
  algolia-scraping:
    runs-on: ubuntu-latest
    #    runs-on: [self-hosted, Linux, X64]
    steps:
      - name: Checkout código
        uses: actions/checkout@v4

      - name: Configurar Docker
        run: |
          docker network create scraping-network

      - name: Construir y ejecutar sitio Docusaurus
        run: |
          docker build -t docusaurus-site .
          docker run -d \
            --name docusaurus-server \
            --network scraping-network \
            -p 3000:3000 \
            docusaurus-site

      - name: Validar servidor funcionando
        timeout-minutes: 3
        run: |
          # Intenta hasta 12 veces con 15 segundos entre cada intento
          for i in {1..12}; do
            HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:3000)
            if [ "$HTTP_STATUS" -eq 200 ]; then
              echo "✅ Servidor funcionando correctamente"
              exit 0
            fi
            echo "⏳ Intento $i/12 - Esperando respuesta (Status: $HTTP_STATUS)"
            sleep 15
          done
          echo "❌ El servidor no respondió con 200 después de 3 minutos"
          exit 1

      - name: Ejecutar scraper Algolia
        run: |
          docker run \
            --network scraping-network \
            -e APPLICATION_ID=${{ secrets.APPLICATION_ID }} \
            -e API_KEY=${{ secrets.API_KEY }} \
            -e "CONFIG=$(cat ./config.docker.json)" \
            algolia/docsearch-scraper

      - name: Limpiar recursos
        if: always()
        run: |
          docker stop docusaurus-server || true
          docker rm docusaurus-server || true
          docker network rm scraping-network || true
